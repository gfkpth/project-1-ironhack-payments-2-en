{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook analyses..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core aspects\n",
    "\n",
    "- cohorts: defined by month of creation of first cash advance (`created_at`)\n",
    "\n",
    "goal:\n",
    "\n",
    "- track monthly evolution of key metrics by cohort\n",
    "\n",
    "key metrics:\n",
    "\n",
    "- frequency of usage of cash advancements over time\n",
    "- incident rate\n",
    "- revenue generated\n",
    "- new relevant metric (TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b8c15",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "1. conduct an exploratory data analysis to gain a comprehensive understanding of the dataset.\n",
    "\n",
    "2. Explore key statistics, distributions, and visualizations to identify patterns and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475936c5",
   "metadata": {},
   "source": [
    "## Data Quality Analysis\n",
    "1. Assess the quality of the dataset by identifying missing values, data inconsistencies, and potential errors.\n",
    "\n",
    "2. Implement data cleaning and preprocessing steps to ensure the reliability of your analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68b5e2",
   "metadata": {},
   "source": [
    "## Calculate and analyze the following metrics for each cohort:\n",
    "\n",
    "1. Frequency of Service Usage: Understand how often users from each cohort utilize IronHack Payments' cash advance services over time.\n",
    "\n",
    "2. Incident Rate: Determine the incident rate, specifically focusing on payment incidents, for each cohort. Identify if there are variations in incident rates among different cohorts.\n",
    "\n",
    "3. Revenue Generated by the Cohort: Calculate the total revenue generated by each cohort over months to assess the financial impact of user behavior.\n",
    "\n",
    "4. New Relevant Metric: Propose and calculate a new relevant metric that provides additional insights into user behavior or the performance of IronHack Payments' services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relevant columns:\n",
    "\n",
    "cashRequest:\n",
    "  - `created_at`\n",
    "  - `updated_at`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef437e1",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "1. Python Code: Provide well-documented Python code that conducts the cohort analysis, including data loading, preprocessing, cohort creation, metric calculation, and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup requirements\n",
    "\n",
    "- extract/define cohorts in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [EDA](#eda)  \n",
    "    a. [Data overview](#data-overview)  \n",
    "    b. [Data cleaning/quality analysis](#data-cleaning/quality-analysis)  \n",
    "    c. [Further EDA](#further-eda)\n",
    "3. [Target data analysis](#target-data-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78423fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef233b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as pltevaluateDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fa26126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we removed the spaces from the csv files so we can easuly import them here\n",
    "\n",
    "# We modified our import process to directly cast proper datatypes for dates.\n",
    "# Float/integer will still be handled in data cleaning, \n",
    "# since some of the offending columns have NaN values causing issues (hence presumably the wrong automatic casting)\n",
    "\n",
    "\n",
    "# lists of columns containing dates\n",
    "\n",
    "datetime_columns_cash_request = [\n",
    "    \"created_at\",\n",
    "    \"updated_at\",\n",
    "    \"moderated_at\",\n",
    "    \"cash_request_received_date\",\n",
    "    \"reimbursement_date\",\n",
    "    \"money_back_date\",\n",
    "    \"send_at\",\n",
    "    \"reco_last_update\",\n",
    "    \"reco_creation\"\n",
    "]\n",
    "   \n",
    "datetime_columns_fees = [\n",
    "    \"created_at\",\n",
    "    \"updated_at\",\n",
    "    \"paid_at\",\n",
    "    \"from_date\",\n",
    "    \"to_date\"\n",
    "]\n",
    "\n",
    "\n",
    "fees = pd.read_csv(\"../project_dataset/extract-fees-dataanalyst.csv\",\n",
    "                            parse_dates = datetime_columns_fees)\n",
    "cashRequest = pd.read_csv(\"../project_dataset/extract-cashrequest-dataanalyst.csv\", \n",
    "                            parse_dates = datetime_columns_cash_request)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe296ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "497205b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cash_request_id</th>\n",
       "      <th>type</th>\n",
       "      <th>status</th>\n",
       "      <th>category</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>reason</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>paid_at</th>\n",
       "      <th>from_date</th>\n",
       "      <th>to_date</th>\n",
       "      <th>charge_moment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6537</td>\n",
       "      <td>14941.0</td>\n",
       "      <td>instant_payment</td>\n",
       "      <td>rejected</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Instant Payment Cash Request 14941</td>\n",
       "      <td>2020-09-07 10:47:27.423150+00:00</td>\n",
       "      <td>2020-10-13 14:25:09.396112+00:00</td>\n",
       "      <td>2020-12-17 14:50:07.47011+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6961</td>\n",
       "      <td>11714.0</td>\n",
       "      <td>incident</td>\n",
       "      <td>accepted</td>\n",
       "      <td>rejected_direct_debit</td>\n",
       "      <td>5.0</td>\n",
       "      <td>rejected direct debit</td>\n",
       "      <td>2020-09-09 20:51:17.998653+00:00</td>\n",
       "      <td>2020-10-13 14:25:15.537063+00:00</td>\n",
       "      <td>2020-12-08 17:13:10.45908+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16296</td>\n",
       "      <td>23371.0</td>\n",
       "      <td>instant_payment</td>\n",
       "      <td>accepted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Instant Payment Cash Request 23371</td>\n",
       "      <td>2020-10-23 10:10:58.352972+00:00</td>\n",
       "      <td>2020-10-23 10:10:58.352994+00:00</td>\n",
       "      <td>2020-11-04 19:34:37.43291+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20775</td>\n",
       "      <td>26772.0</td>\n",
       "      <td>instant_payment</td>\n",
       "      <td>accepted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Instant Payment Cash Request 26772</td>\n",
       "      <td>2020-10-31 15:46:53.643958+00:00</td>\n",
       "      <td>2020-10-31 15:46:53.643982+00:00</td>\n",
       "      <td>2020-11-19 05:09:22.500223+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11242</td>\n",
       "      <td>19350.0</td>\n",
       "      <td>instant_payment</td>\n",
       "      <td>accepted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Instant Payment Cash Request 19350</td>\n",
       "      <td>2020-10-06 08:20:17.170432+00:00</td>\n",
       "      <td>2020-10-13 14:25:03.267983+00:00</td>\n",
       "      <td>2020-11-02 14:45:20.355598+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  cash_request_id             type    status               category  \\\n",
       "0   6537          14941.0  instant_payment  rejected                    NaN   \n",
       "1   6961          11714.0         incident  accepted  rejected_direct_debit   \n",
       "2  16296          23371.0  instant_payment  accepted                    NaN   \n",
       "3  20775          26772.0  instant_payment  accepted                    NaN   \n",
       "4  11242          19350.0  instant_payment  accepted                    NaN   \n",
       "\n",
       "   total_amount                              reason  \\\n",
       "0           5.0  Instant Payment Cash Request 14941   \n",
       "1           5.0               rejected direct debit   \n",
       "2           5.0  Instant Payment Cash Request 23371   \n",
       "3           5.0  Instant Payment Cash Request 26772   \n",
       "4           5.0  Instant Payment Cash Request 19350   \n",
       "\n",
       "                        created_at                       updated_at  \\\n",
       "0 2020-09-07 10:47:27.423150+00:00 2020-10-13 14:25:09.396112+00:00   \n",
       "1 2020-09-09 20:51:17.998653+00:00 2020-10-13 14:25:15.537063+00:00   \n",
       "2 2020-10-23 10:10:58.352972+00:00 2020-10-23 10:10:58.352994+00:00   \n",
       "3 2020-10-31 15:46:53.643958+00:00 2020-10-31 15:46:53.643982+00:00   \n",
       "4 2020-10-06 08:20:17.170432+00:00 2020-10-13 14:25:03.267983+00:00   \n",
       "\n",
       "                         paid_at from_date to_date charge_moment  \n",
       "0   2020-12-17 14:50:07.47011+00       NaN     NaN         after  \n",
       "1   2020-12-08 17:13:10.45908+00       NaN     NaN         after  \n",
       "2   2020-11-04 19:34:37.43291+00       NaN     NaN         after  \n",
       "3  2020-11-19 05:09:22.500223+00       NaN     NaN         after  \n",
       "4  2020-11-02 14:45:20.355598+00       NaN     NaN         after  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is how we get a small insight in the data\n",
    "display(fees.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2688c4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21061 entries, 0 to 21060\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   id               21061 non-null  int64              \n",
      " 1   cash_request_id  21057 non-null  float64            \n",
      " 2   type             21061 non-null  object             \n",
      " 3   status           21061 non-null  object             \n",
      " 4   category         2196 non-null   object             \n",
      " 5   total_amount     21061 non-null  float64            \n",
      " 6   reason           21061 non-null  object             \n",
      " 7   created_at       21061 non-null  datetime64[ns, UTC]\n",
      " 8   updated_at       21061 non-null  datetime64[ns, UTC]\n",
      " 9   paid_at          15531 non-null  object             \n",
      " 10  from_date        7766 non-null   object             \n",
      " 11  to_date          7766 non-null   object             \n",
      " 12  charge_moment    21061 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](2), float64(2), int64(1), object(8)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Overview of data in fees\n",
    "fees.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa623f37",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "- `cash_request_id` is automatically cast as float64. `int` might be more plausible, change in cleaning\n",
    "- date-related columns (`created_at`,`updated__at`,`paid_at`,`from_date`,`to_date`) will need special treatment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- after date casting at import still trouble for `paid_at`,`from_date`,`to_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e677c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount</th>\n",
       "      <th>status</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>moderated_at</th>\n",
       "      <th>deleted_account_id</th>\n",
       "      <th>reimbursement_date</th>\n",
       "      <th>cash_request_received_date</th>\n",
       "      <th>money_back_date</th>\n",
       "      <th>transfer_type</th>\n",
       "      <th>send_at</th>\n",
       "      <th>recovery_status</th>\n",
       "      <th>reco_creation</th>\n",
       "      <th>reco_last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>2019-12-10 19:05:21.596873+00:00</td>\n",
       "      <td>2019-12-11 16:47:42.407830+00:00</td>\n",
       "      <td>804.0</td>\n",
       "      <td>2019-12-11 16:47:42.405646+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-09 19:05:21.596363+00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>regular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>100.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>2019-12-10 19:50:12.347780+00:00</td>\n",
       "      <td>2019-12-11 14:24:22.900054+00:00</td>\n",
       "      <td>231.0</td>\n",
       "      <td>2019-12-11 14:24:22.897988+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-09 19:50:12.34778+00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>regular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>2019-12-10 19:13:35.825460+00:00</td>\n",
       "      <td>2019-12-11 09:46:59.779773+00:00</td>\n",
       "      <td>191.0</td>\n",
       "      <td>2019-12-11 09:46:59.777728+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-09 19:13:35.825041+00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>regular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>99.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>2019-12-10 19:16:10.880172+00:00</td>\n",
       "      <td>2019-12-18 14:26:18.136163+00:00</td>\n",
       "      <td>761.0</td>\n",
       "      <td>2019-12-18 14:26:18.128407+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-09 19:16:10.879606+00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>regular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1594</td>\n",
       "      <td>100.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>2020-05-06 09:59:38.877376+00:00</td>\n",
       "      <td>2020-05-07 09:21:55.340080+00:00</td>\n",
       "      <td>7686.0</td>\n",
       "      <td>2020-05-07 09:21:55.320193+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-05 22:00:00+00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>regular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  amount    status                       created_at  \\\n",
       "0     5   100.0  rejected 2019-12-10 19:05:21.596873+00:00   \n",
       "1    70   100.0  rejected 2019-12-10 19:50:12.347780+00:00   \n",
       "2     7   100.0  rejected 2019-12-10 19:13:35.825460+00:00   \n",
       "3    10    99.0  rejected 2019-12-10 19:16:10.880172+00:00   \n",
       "4  1594   100.0  rejected 2020-05-06 09:59:38.877376+00:00   \n",
       "\n",
       "                        updated_at  user_id                   moderated_at  \\\n",
       "0 2019-12-11 16:47:42.407830+00:00    804.0  2019-12-11 16:47:42.405646+00   \n",
       "1 2019-12-11 14:24:22.900054+00:00    231.0  2019-12-11 14:24:22.897988+00   \n",
       "2 2019-12-11 09:46:59.779773+00:00    191.0  2019-12-11 09:46:59.777728+00   \n",
       "3 2019-12-18 14:26:18.136163+00:00    761.0  2019-12-18 14:26:18.128407+00   \n",
       "4 2020-05-07 09:21:55.340080+00:00   7686.0  2020-05-07 09:21:55.320193+00   \n",
       "\n",
       "   deleted_account_id             reimbursement_date  \\\n",
       "0                 NaN  2020-01-09 19:05:21.596363+00   \n",
       "1                 NaN   2020-01-09 19:50:12.34778+00   \n",
       "2                 NaN  2020-01-09 19:13:35.825041+00   \n",
       "3                 NaN  2020-01-09 19:16:10.879606+00   \n",
       "4                 NaN         2020-06-05 22:00:00+00   \n",
       "\n",
       "  cash_request_received_date money_back_date transfer_type send_at  \\\n",
       "0                        NaT             NaN       regular     NaN   \n",
       "1                        NaT             NaN       regular     NaN   \n",
       "2                        NaT             NaN       regular     NaN   \n",
       "3                        NaT             NaN       regular     NaN   \n",
       "4                        NaT             NaN       regular     NaN   \n",
       "\n",
       "  recovery_status reco_creation reco_last_update  \n",
       "0             NaN           NaT              NaT  \n",
       "1             NaN           NaT              NaT  \n",
       "2             NaN           NaT              NaT  \n",
       "3             NaN           NaT              NaT  \n",
       "4             NaN           NaT              NaT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cashRequest.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93d5153c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23970 entries, 0 to 23969\n",
      "Data columns (total 16 columns):\n",
      " #   Column                      Non-Null Count  Dtype              \n",
      "---  ------                      --------------  -----              \n",
      " 0   id                          23970 non-null  int64              \n",
      " 1   amount                      23970 non-null  float64            \n",
      " 2   status                      23970 non-null  object             \n",
      " 3   created_at                  23970 non-null  datetime64[ns, UTC]\n",
      " 4   updated_at                  23970 non-null  datetime64[ns, UTC]\n",
      " 5   user_id                     21867 non-null  float64            \n",
      " 6   moderated_at                16035 non-null  object             \n",
      " 7   deleted_account_id          2104 non-null   float64            \n",
      " 8   reimbursement_date          23970 non-null  object             \n",
      " 9   cash_request_received_date  16289 non-null  datetime64[ns]     \n",
      " 10  money_back_date             16543 non-null  object             \n",
      " 11  transfer_type               23970 non-null  object             \n",
      " 12  send_at                     16641 non-null  object             \n",
      " 13  recovery_status             3330 non-null   object             \n",
      " 14  reco_creation               3330 non-null   datetime64[ns, UTC]\n",
      " 15  reco_last_update            3330 non-null   datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](4), datetime64[ns](1), float64(3), int64(1), object(7)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Overview of data in cashRequest\n",
    "cashRequest.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c1315",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "- `delete_account_id` and `user_id` needn't be floats (cast to int later)\n",
    "- date-related columns (`created_at`,`updated__at`,`moderated_at`...) will need special treatment\n",
    "- fewer unique `user_id` values than cashRequest `id`s: indicating multiple transactions for some users or actual missing values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- after date casting at import the following fields are still `object` rather than `datetime`:\n",
    "  `moderated_at`,`reimbursement_date`,`money_back_date`,`send_at`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38a1b952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of records\n",
      "23970\n",
      "\n",
      "Empty columns\n",
      "id                                0\n",
      "amount                            0\n",
      "status                            0\n",
      "created_at                        0\n",
      "updated_at                        0\n",
      "user_id                        2103\n",
      "moderated_at                   7935\n",
      "deleted_account_id            21866\n",
      "reimbursement_date                0\n",
      "cash_request_received_date     7681\n",
      "money_back_date                7427\n",
      "transfer_type                     0\n",
      "send_at                        7329\n",
      "recovery_status               20640\n",
      "reco_creation                 20640\n",
      "reco_last_update              20640\n",
      "dtype: int64\n",
      "\n",
      "Unique columns\n",
      "id                            23970\n",
      "amount                           41\n",
      "status                            7\n",
      "created_at                    23970\n",
      "updated_at                    23970\n",
      "user_id                       10798\n",
      "moderated_at                  16035\n",
      "deleted_account_id             1141\n",
      "reimbursement_date             4089\n",
      "cash_request_received_date      312\n",
      "money_back_date               12221\n",
      "transfer_type                     2\n",
      "send_at                       16641\n",
      "recovery_status                   4\n",
      "reco_creation                  3330\n",
      "reco_last_update               3330\n",
      "dtype: int64\n",
      "\n",
      "DataFrame info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21061 entries, 0 to 21060\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   id               21061 non-null  int64              \n",
      " 1   cash_request_id  21057 non-null  float64            \n",
      " 2   type             21061 non-null  object             \n",
      " 3   status           21061 non-null  object             \n",
      " 4   category         2196 non-null   object             \n",
      " 5   total_amount     21061 non-null  float64            \n",
      " 6   reason           21061 non-null  object             \n",
      " 7   created_at       21061 non-null  datetime64[ns, UTC]\n",
      " 8   updated_at       21061 non-null  datetime64[ns, UTC]\n",
      " 9   paid_at          15531 non-null  object             \n",
      " 10  from_date        7766 non-null   object             \n",
      " 11  to_date          7766 non-null   object             \n",
      " 12  charge_moment    21061 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](2), float64(2), int64(1), object(8)\n",
      "memory usage: 2.1+ MB\n",
      "\n",
      "Total amount of records\n",
      "21061\n",
      "\n",
      "Empty columns\n",
      "id                     0\n",
      "cash_request_id        4\n",
      "type                   0\n",
      "status                 0\n",
      "category           18865\n",
      "total_amount           0\n",
      "reason                 0\n",
      "created_at             0\n",
      "updated_at             0\n",
      "paid_at             5530\n",
      "from_date          13295\n",
      "to_date            13295\n",
      "charge_moment          0\n",
      "dtype: int64\n",
      "\n",
      "Unique columns\n",
      "id                 21061\n",
      "cash_request_id    12933\n",
      "type                   3\n",
      "status                 4\n",
      "category               2\n",
      "total_amount           2\n",
      "reason             15149\n",
      "created_at         21026\n",
      "updated_at         21061\n",
      "paid_at            15529\n",
      "from_date           1084\n",
      "to_date             1560\n",
      "charge_moment          2\n",
      "dtype: int64\n",
      "\n",
      "DataFrame info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21061 entries, 0 to 21060\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   id               21061 non-null  int64              \n",
      " 1   cash_request_id  21057 non-null  float64            \n",
      " 2   type             21061 non-null  object             \n",
      " 3   status           21061 non-null  object             \n",
      " 4   category         2196 non-null   object             \n",
      " 5   total_amount     21061 non-null  float64            \n",
      " 6   reason           21061 non-null  object             \n",
      " 7   created_at       21061 non-null  datetime64[ns, UTC]\n",
      " 8   updated_at       21061 non-null  datetime64[ns, UTC]\n",
      " 9   paid_at          15531 non-null  object             \n",
      " 10  from_date        7766 non-null   object             \n",
      " 11  to_date          7766 non-null   object             \n",
      " 12  charge_moment    21061 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](2), float64(2), int64(1), object(8)\n",
      "memory usage: 2.1+ MB\n",
      "\n",
      "=== cashRequest ===\n",
      "Numerical columns (4): ['id', 'amount', 'user_id', 'deleted_account_id']\n",
      "Categorical columns (7): ['status', 'moderated_at', 'reimbursement_date', 'money_back_date', 'transfer_type', 'send_at', 'recovery_status']\n",
      "Date columns (1): ['cash_request_received_date']\n",
      "\n",
      "=== fees ===\n",
      "Numerical columns (3): ['id', 'cash_request_id', 'total_amount']\n",
      "Categorical columns (8): ['type', 'status', 'category', 'reason', 'paid_at', 'from_date', 'to_date', 'charge_moment']\n",
      "Date columns (0): []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluateDataFrame(df):\n",
    "    # Lets check how many values we actually have\n",
    "    print(\"Total amount of records\")\n",
    "    print(len(df))\n",
    "    print()\n",
    "    # This shows us the amount of empty items for each column \n",
    "    print(\"Empty columns\")\n",
    "    print(df.isnull().sum())\n",
    "    print()\n",
    "    # check which columns are unique \n",
    "    print(\"Unique columns\")\n",
    "    print(df.nunique())\n",
    "    print()\n",
    "    print(\"DataFrame info\")\n",
    "    fees.info()\n",
    "    print()\n",
    "    \n",
    "evaluateDataFrame(cashRequest)\n",
    "evaluateDataFrame(fees)\n",
    "\n",
    "def inspect_data_types(df, name=\"DataFrame\"):\n",
    "    print(f\"=== {name} ===\")\n",
    "    numerical = df.select_dtypes(include='number').columns.tolist()\n",
    "    categorical = df.select_dtypes(include='object').columns.tolist()\n",
    "    datetime = df.select_dtypes(include='datetime').columns.tolist()\n",
    "      \n",
    "    print(f\"Numerical columns ({len(numerical)}): {numerical}\")\n",
    "    print(f\"Categorical columns ({len(categorical)}): {categorical}\")\n",
    "    print(f\"Date columns ({len(datetime)}): {datetime}\")\n",
    "    print()\n",
    "\n",
    "inspect_data_types(cashRequest, name=\"cashRequest\")\n",
    "inspect_data_types(fees, name=\"fees\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "- 2103 empty values in `cashRequest.user_id` corresponding to the difference to `id` noted above\n",
    "  - also: very close to value of `deleted_account` id (2104), so possible relation to that\n",
    "- fees are associated to cashRequests via `cash_request_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used these insights to adapt our data import in order to directly cast the correct datatypes for columns that were not correctly identified automatically.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91415d5",
   "metadata": {},
   "source": [
    "## Data cleaning/quality analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4b3feb",
   "metadata": {},
   "source": [
    "### Instructions after EDA\n",
    "1. Parse all values to the right data types\n",
    "2. remove loose items (like fees without cashRequest)\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fa41786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the start and ends of all column names so we get no suprises in the data retrieval later\n",
    "fees.columns = fees.columns.str.strip()\n",
    "cashRequest.columns = cashRequest.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block is going to fix datatypes for both dataframes, i.e. fixing the missing dates and casting some columns as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e186a6d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert NA to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# This currently doesn't work with astype(int), while astype(\"Int64\")\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m float_to_int_fees:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m      fees[col] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfees\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcoerce\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m float_to_int_cash_request = [\n\u001b[32m     42\u001b[39m \n\u001b[32m     43\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33muser_id\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     44\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdeleted_account_id\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     45\u001b[39m ]\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m float_to_int_cash_request:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studium/2024-Professional development/Courses/Ironhack/Data Science and ML/.iron-venv/lib/python3.11/site-packages/pandas/core/generic.py:6643\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6637\u001b[39m     results = [\n\u001b[32m   6638\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6639\u001b[39m     ]\n\u001b[32m   6641\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6642\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6643\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6644\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6645\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studium/2024-Professional development/Courses/Ironhack/Data Science and ML/.iron-venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:430\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    428\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studium/2024-Professional development/Courses/Ironhack/Data Science and ML/.iron-venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studium/2024-Professional development/Courses/Ironhack/Data Science and ML/.iron-venv/lib/python3.11/site-packages/pandas/core/internals/blocks.py:758\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    755\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    756\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    762\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studium/2024-Professional development/Courses/Ironhack/Data Science and ML/.iron-venv/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studium/2024-Professional development/Courses/Ironhack/Data Science and ML/.iron-venv/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:179\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np.ndarray):\n\u001b[32m    178\u001b[39m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     values = \u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    182\u001b[39m     values = _astype_nansafe(values, dtype, copy=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/studium/2024-Professional development/Courses/Ironhack/Data Science and ML/.iron-venv/lib/python3.11/site-packages/pandas/core/arrays/masked.py:586\u001b[39m, in \u001b[36mBaseMaskedArray.astype\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m    584\u001b[39m \u001b[38;5;66;03m# to_numpy will also raise, but we get somewhat nicer exception messages here\u001b[39;00m\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._hasna:\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot convert NA to integer\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype.kind == \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._hasna:\n\u001b[32m    588\u001b[39m     \u001b[38;5;66;03m# careful: astype_nansafe converts np.nan to True\u001b[39;00m\n\u001b[32m    589\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot convert float NaN to bool\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: cannot convert NA to integer"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is antoher option of parsing datatypes\n",
    "# errors=\"coerce\" -> means that erroes will force conversion and replace any invalid or unconvertible values with NaT\n",
    "datetime_columns_cash_request = [\n",
    "    \"created_at\",\n",
    "    \"updated_at\",\n",
    "    \"moderated_at\",\n",
    "    \"cash_request_received_date\",\n",
    "    \"reimbursement_date\",\n",
    "    \"money_back_date\",\n",
    "    \"send_at\",\n",
    "    \"reco_last_update\",\n",
    "    \"reco_creation\"\n",
    "]\n",
    "\n",
    "for col in datetime_columns_cash_request:\n",
    "    cashRequest[col] = pd.to_datetime(cashRequest[col], errors=\"coerce\")\n",
    "    \n",
    "datetime_columns_fees = [\n",
    "    \"created_at\",\n",
    "    \"updated_at\",\n",
    "    \"paid_at\",\n",
    "    \"from_date\",\n",
    "    \"to_date\"\n",
    "]\n",
    "\n",
    "for col in datetime_columns_fees:\n",
    "    fees[col] = pd.to_datetime(fees[col], errors=\"coerce\")\n",
    "    \n",
    "\n",
    "\n",
    "float_to_int_fees = [\n",
    " \n",
    "    \"cash_request_id\"\n",
    "]\n",
    "\n",
    "# This currently doesn't work with astype(int), while astype(\"Int64\")\n",
    "\n",
    "for col in float_to_int_fees:\n",
    "     fees[col] = pd.to_numeric(fees[col], errors=\"coerce\").astype(int)\n",
    "     \n",
    "float_to_int_cash_request = [\n",
    " \n",
    "    \"user_id\",\n",
    "    \"deleted_account_id\"\n",
    "]\n",
    "\n",
    "for col in float_to_int_cash_request:\n",
    "     cashRequest[col] = pd.to_numeric(cashRequest[col], errors=\"coerce\").astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21061 entries, 0 to 21060\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   id               21061 non-null  int64              \n",
      " 1   cash_request_id  21057 non-null  Int64              \n",
      " 2   type             21061 non-null  object             \n",
      " 3   status           21061 non-null  object             \n",
      " 4   category         2196 non-null   object             \n",
      " 5   total_amount     21061 non-null  float64            \n",
      " 6   reason           21061 non-null  object             \n",
      " 7   created_at       21061 non-null  datetime64[ns, UTC]\n",
      " 8   updated_at       21061 non-null  datetime64[ns, UTC]\n",
      " 9   paid_at          15438 non-null  datetime64[ns, UTC]\n",
      " 10  from_date        6749 non-null   datetime64[ns, UTC]\n",
      " 11  to_date          6512 non-null   datetime64[ns, UTC]\n",
      " 12  charge_moment    21061 non-null  object             \n",
      "dtypes: Int64(1), datetime64[ns, UTC](5), float64(1), int64(1), object(5)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "fees.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23970 entries, 0 to 23969\n",
      "Data columns (total 16 columns):\n",
      " #   Column                      Non-Null Count  Dtype              \n",
      "---  ------                      --------------  -----              \n",
      " 0   id                          23970 non-null  int64              \n",
      " 1   amount                      23970 non-null  float64            \n",
      " 2   status                      23970 non-null  object             \n",
      " 3   created_at                  23970 non-null  datetime64[ns, UTC]\n",
      " 4   updated_at                  23970 non-null  datetime64[ns, UTC]\n",
      " 5   user_id                     21867 non-null  Int64              \n",
      " 6   moderated_at                15912 non-null  datetime64[ns, UTC]\n",
      " 7   deleted_account_id          2104 non-null   Int64              \n",
      " 8   reimbursement_date          3050 non-null   datetime64[ns, UTC]\n",
      " 9   cash_request_received_date  16289 non-null  datetime64[ns]     \n",
      " 10  money_back_date             12040 non-null  datetime64[ns, UTC]\n",
      " 11  transfer_type               23970 non-null  object             \n",
      " 12  send_at                     16466 non-null  datetime64[ns, UTC]\n",
      " 13  recovery_status             3330 non-null   object             \n",
      " 14  reco_creation               3330 non-null   datetime64[ns, UTC]\n",
      " 15  reco_last_update            3330 non-null   datetime64[ns, UTC]\n",
      "dtypes: Int64(2), datetime64[ns, UTC](8), datetime64[ns](1), float64(1), int64(1), object(3)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "cashRequest.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
