{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook analyses..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core aspects\n",
    "\n",
    "- cohorts: defined by month of creation of first cash advance (`created_at`)\n",
    "\n",
    "goal:\n",
    "\n",
    "- track monthly evolution of key metrics by cohort\n",
    "\n",
    "key metrics:\n",
    "\n",
    "- frequency of usage of cash advancements over time\n",
    "- incident rate\n",
    "- revenue generated\n",
    "- new relevant metric (TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b8c15",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "1. conduct an exploratory data analysis to gain a comprehensive understanding of the dataset.\n",
    "\n",
    "2. Explore key statistics, distributions, and visualizations to identify patterns and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475936c5",
   "metadata": {},
   "source": [
    "## Data Quality Analysis\n",
    "1. Assess the quality of the dataset by identifying missing values, data inconsistencies, and potential errors.\n",
    "\n",
    "2. Implement data cleaning and preprocessing steps to ensure the reliability of your analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68b5e2",
   "metadata": {},
   "source": [
    "## Calculate and analyze the following metrics for each cohort:\n",
    "\n",
    "1. Frequency of Service Usage: Understand how often users from each cohort utilize IronHack Payments' cash advance services over time.\n",
    "\n",
    "2. Incident Rate: Determine the incident rate, specifically focusing on payment incidents, for each cohort. Identify if there are variations in incident rates among different cohorts.\n",
    "\n",
    "3. Revenue Generated by the Cohort: Calculate the total revenue generated by each cohort over months to assess the financial impact of user behavior.\n",
    "\n",
    "4. New Relevant Metric: Propose and calculate a new relevant metric that provides additional insights into user behavior or the performance of IronHack Payments' services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relevant columns:\n",
    "\n",
    "cashRequest:\n",
    "  - `created_at`\n",
    "  - `updated_at`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef437e1",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "1. Python Code: Provide well-documented Python code that conducts the cohort analysis, including data loading, preprocessing, cohort creation, metric calculation, and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup requirements\n",
    "\n",
    "- extract/define cohorts in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [EDA](#eda)  \n",
    "    a. [Data overview](#data-overview)  \n",
    "    b. [Data cleaning/quality analysis](#data-cleaning/quality-analysis)  \n",
    "    c. [Further EDA](#further-eda)\n",
    "3. [Target data analysis](#target-data-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78423fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef233b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa26126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we removed the spaces from the csv files so we can easuly import them here\n",
    "\n",
    "# We modified our import process to directly cast proper datatypes for dates.\n",
    "# Float/integer will still be handled in data cleaning, \n",
    "# since some of the offending columns have NaN values causing issues (hence presumably the wrong automatic casting)\n",
    "\n",
    "\n",
    "# lists of columns containing dates\n",
    "\n",
    "datetime_columns_cash_request = [\n",
    "    \"created_at\",\n",
    "    \"updated_at\",\n",
    "    \"moderated_at\",\n",
    "    \"cash_request_received_date\",\n",
    "    \"reimbursement_date\",\n",
    "    \"money_back_date\",\n",
    "    \"send_at\",\n",
    "    \"reco_last_update\",\n",
    "    \"reco_creation\"\n",
    "]\n",
    "   \n",
    "datetime_columns_fees = [\n",
    "    \"created_at\",\n",
    "    \"updated_at\",\n",
    "    \"paid_at\",\n",
    "    \"from_date\",\n",
    "    \"to_date\"\n",
    "]\n",
    "\n",
    "\n",
    "fees = pd.read_csv(\"../project_dataset/extract-fees-dataanalyst.csv\",\n",
    "                            parse_dates = datetime_columns_fees)\n",
    "cashRequest = pd.read_csv(\"../project_dataset/extract-cashrequest-dataanalyst.csv\", \n",
    "                            parse_dates = datetime_columns_cash_request)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497205b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we get a small insight in the data\n",
    "display(fees.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2688c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of data in fees\n",
    "fees.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa623f37",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "- `cash_request_id` is automatically cast as float64. `int` might be more plausible, change in cleaning\n",
    "- date-related columns (`created_at`,`updated__at`,`paid_at`,`from_date`,`to_date`) will need special treatment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- after date casting at import still trouble for `paid_at`,`from_date`,`to_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e677c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cashRequest.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d5153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of data in cashRequest\n",
    "cashRequest.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c1315",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "- `delete_account_id` and `user_id` needn't be floats (cast to int later)\n",
    "- date-related columns (`created_at`,`updated__at`,`moderated_at`...) will need special treatment\n",
    "- fewer unique `user_id` values than cashRequest `id`s: indicating multiple transactions for some users or actual missing values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- after date casting at import the following fields are still `object` rather than `datetime`:\n",
    "  `moderated_at`,`reimbursement_date`,`money_back_date`,`send_at`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def evaluateDataFrame(df):\n",
    "    # Lets check how many values we actually have\n",
    "    print(\"Total amount of records\")\n",
    "    print(len(df))\n",
    "    print()\n",
    "    # This shows us the amount of empty rows for each column \n",
    "    print(\"Empty rows\")\n",
    "    print(df.isnull().sum())\n",
    "    print()\n",
    "    # check the number of unique values for each column \n",
    "    print(\"Unique rows\")\n",
    "    print(df.nunique())\n",
    "    print()\n",
    "    #print(\"DataFrame info\")            # we're already calling this earlier, might make sense for plain-py version (although then we could put info() at start and remove len, since that's also displayed by info())\n",
    "    #fees.info()\n",
    "    #print()\n",
    "    \n",
    "\n",
    "def inspect_data_types(df, name=\"DataFrame\"):\n",
    "    print(f\"=== {name} ===\")\n",
    "    numerical = df.select_dtypes(include='number').columns.tolist()\n",
    "    categorical = df.select_dtypes(include='object').columns.tolist()\n",
    "    datetime = df.select_dtypes(include=['datetime','datetime64','datetime64[ns, UTC]']).columns.tolist()\n",
    "      \n",
    "    print(f\"Numerical columns ({len(numerical)}): {numerical}\")\n",
    "    print(f\"Categorical columns ({len(categorical)}): {categorical}\")\n",
    "    print(f\"Date columns ({len(datetime)}): {datetime}\")\n",
    "    print()\n",
    "    \n",
    "    return numerical, categorical, datetime         # modified to also return the lists for further use\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling functions\n",
    "# commented for now, piecewise presentation might be more readable in notebook \n",
    "\n",
    "# evaluateDataFrame(cashRequest)\n",
    "# evaluateDataFrame(fees)\n",
    "\n",
    "# inspect_data_types(cashRequest)\n",
    "# inspect_data_types(fees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cashRequest.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cashRequest.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fees.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fees.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fees['total_amount'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fees[['category','total_amount']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only two types of fees are levied: 5 and 10 Euros(?) - maybe convert to int as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cashr_numcols, cashr_strcols, cashr_dtcols = inspect_data_types(cashRequest, name=\"cashRequest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fees_numcols, fees_strcols, fees_dtcols = inspect_data_types(fees, name=\"fees\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several of the date fields aren't typed correctly, fix in data cleaning and rerun function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "- 2103 empty values in `cashRequest.user_id` corresponding to the difference to `id` noted above\n",
    "  - also: very close to value of `deleted_account` id (2104), so possible relation to that\n",
    "- fees are associated to cashRequests via `cash_request_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used these insights to adapt our data import in order to directly cast the correct datatypes for columns that were not correctly identified automatically.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91415d5",
   "metadata": {},
   "source": [
    "## Data cleaning/quality analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4b3feb",
   "metadata": {},
   "source": [
    "### Instructions after EDA\n",
    "1. Parse all values to the right data types\n",
    "2. remove loose items (like fees without cashRequest)\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa41786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the start and ends of all column names so we get no suprises in the data retrieval later\n",
    "fees.columns = fees.columns.str.strip()\n",
    "cashRequest.columns = cashRequest.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block is going to fix datatypes for both dataframes, i.e. fixing the missing dates and casting some columns as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is antoher option of parsing datatypes\n",
    "# errors=\"coerce\" -> means that erroes will force conversion and replace any invalid or unconvertible values with NaT\n",
    "datetime_columns_cash_request = [\n",
    "    \"created_at\",\n",
    "    \"updated_at\",\n",
    "    \"moderated_at\",\n",
    "    \"cash_request_received_date\",\n",
    "    \"reimbursement_date\",\n",
    "    \"money_back_date\",\n",
    "    \"send_at\",\n",
    "    \"reco_last_update\",\n",
    "    \"reco_creation\"\n",
    "]\n",
    "\n",
    "for col in datetime_columns_cash_request:\n",
    "    cashRequest[col] = pd.to_datetime(cashRequest[col], errors=\"coerce\")\n",
    "    \n",
    "datetime_columns_fees = [\n",
    "    \"created_at\",\n",
    "    \"updated_at\",\n",
    "    \"paid_at\",\n",
    "    \"from_date\",\n",
    "    \"to_date\"\n",
    "]\n",
    "\n",
    "for col in datetime_columns_fees:\n",
    "    fees[col] = pd.to_datetime(fees[col], errors=\"coerce\")\n",
    "    \n",
    "\n",
    "\n",
    "float_to_int_fees = [\n",
    "    \"cash_request_id\",\n",
    "    \"id\"\n",
    "]\n",
    "\n",
    "# This currently doesn't work with astype(int), while astype(\"Int64\")\n",
    "for col in float_to_int_fees:\n",
    "    fees[col] = pd.to_numeric(fees[col], errors=\"coerce\").astype(\"Int64\")\n",
    "     \n",
    "float_to_int_cash_request = [\n",
    "    \"user_id\",\n",
    "    \"deleted_account_id\",\n",
    "    \"id\"\n",
    "]\n",
    "\n",
    "for col in float_to_int_cash_request:\n",
    "    cashRequest[col] = pd.to_numeric(cashRequest[col], errors=\"coerce\").astype(\"Int64\")\n",
    "    \n",
    "fees.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cashRequest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cashr_numcols, cashr_strcols, cashr_dtcols = inspect_data_types(cashRequest, name=\"cashRequest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fees.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fees_numcols, fees_strcols, fees_dtcols = inspect_data_types(fees, name=\"fees\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning floats that should be ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fees[fees['cash_request_id'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NA-values in `fees.cash_request_id` are for cancelled transactions - let's drop them!(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating copies before dropping values (optional)\n",
    "fees_cp = fees.copy()\n",
    "cashRequest_cp = cashRequest.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows that have are not connected to a cash request anymore\n",
    "fees_cp.dropna(subset=['cash_request_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fees_cp['cash_request_id'] = fees_cp['cash_request_id'].astype(int)\n",
    "fees_cp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking NaT dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check date fields with missing data to assess significance\n",
    "for col in cashr_dtcols:\n",
    "    if cashRequest_cp[col].isna().sum() > 0:\n",
    "        print(col, ': ', cashRequest_cp[col].isna().sum())       \n",
    "        # display(cashRequest_cp[cashRequest_cp[col].isna()].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note sure if we might want to merge the datasets much earlier?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left-join the fees dataframe to the cashRequest dataframe on `id`/`cash_request_id` to create full dataset:\n",
    "(We want to retain all cash requests even in case they have no associated fees.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cashRequest_cp.merge(fees_cp, how='left', left_on='id', right_on='cash_request_id')\n",
    "print(len(cashRequest_cp))\n",
    "print(len(fees_cp))\n",
    "print(len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6425da6e",
   "metadata": {},
   "source": [
    "## Further EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group on fees > cash_request_id and count the amount of items -> this will return us the amount of fees per cash_request_id\n",
    "\n",
    "fee_counts = fees_cp.groupby('cash_request_id').size()\n",
    "\n",
    "# This returns us all the cash_requests that have multiple fees \n",
    "multiple_fees = fee_counts[fee_counts > 1]\n",
    "\n",
    "# Show them\n",
    "# print(multiple_fees)\n",
    "print(len(df))\n",
    "print(df.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babac284",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf827f4e",
   "metadata": {},
   "source": [
    "# Target data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8008a9",
   "metadata": {},
   "source": [
    "## Overview of cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69efa381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column with the created_at converted to the month annotation like 2024-03-18, 2023-11-02 etc -> these can be used to be labels for the plot\n",
    "cashRequest_cp['cohort_month'] = cashRequest_cp['created_at'].dt.to_period('M')\n",
    "\n",
    "# This groupes the data by the newly generated column and takes the count of cashrequest that happened in eacht period\n",
    "time_plot_data = cashRequest_cp.groupby('cohort_month')['user_id'].count()\n",
    "# print(time_plot_data)\n",
    "time_plot_data.plot(kind='line')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
