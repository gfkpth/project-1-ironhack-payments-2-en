{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81bedfa1",
   "metadata": {},
   "source": [
    "# Cohort Analysis Project – IronHack Payments\n",
    "\n",
    "## 📌 Introduction\n",
    "\n",
    "IronHack Payments, founded in 2020, offers innovative cash advance solutions with transparent pricing and no hidden fees. This project aims to uncover user behavior patterns using cohort analysis, helping IronHack Payments further optimize its services.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧭 Project Overview\n",
    "\n",
    "The goal is to analyze user cohorts defined by the month in which users made their **first cash advance request**. By tracking key metrics over time per cohort, we aim to provide actionable insights into usage behavior and financial performance.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Metrics to Analyze\n",
    "\n",
    "We will compute and analyze the following metrics for each cohort:\n",
    "\n",
    "1. **Frequency of Service Usage**\n",
    "    Understand how often users from each cohort utilize IronHack Payments' cash advance services over time.\n",
    "\n",
    "2. **Incident Rate**\n",
    "    Determine the incident rate, specifically focusing on payment incidents, for each cohort. Identify if there are variations in incident rates among different cohorts.\n",
    "\n",
    "3. **Revenue Generated by the Cohort**\n",
    "    Calculate the total revenue generated by each cohort over months to assess the financial impact of user behavior.\n",
    "\n",
    "4. **New Relevant Metric (Optional)**\n",
    "   Propose and calculate a new relevant metric that provides additional insights into user behavior or the performance of IronHack Payments' services.\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Data Analysis Tools\n",
    "\n",
    "- **Language:** Python (primary)\n",
    "- **Libraries:**\n",
    "  - `pandas` for data cleaning and manipulation\n",
    "  - `matplotlib` / `seaborn` for visualization\n",
    "---\n",
    "\n",
    "## 🔎 Exploratory Data Analysis (EDA)\n",
    "\n",
    "Before conducting the cohort analysis:\n",
    "\n",
    "- Inspect dataset structure and column types\n",
    "- View summary statistics using `.describe()`\n",
    "- Explore distributions and detect outliers\n",
    "- Examine timestamp formats and identify feature gaps\n",
    "\n",
    "Example EDA:\n",
    "- Count of cash requests per month\n",
    "- Distribution of advance amounts\n",
    "- Frequency of payment incidents\n",
    "\n",
    "---\n",
    "\n",
    "## 🧹 Data Quality Analysis\n",
    "\n",
    "Check for and address:\n",
    "\n",
    "- Missing values (`.isnull().sum()`)\n",
    "- Duplicate records\n",
    "- Inconsistent or malformed dates\n",
    "- Incorrect data types (e.g., strings instead of numeric)\n",
    "\n",
    "Document all issues found and how they were handled (e.g., dropped rows, converted types, filled values).\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Deliverables\n",
    "\n",
    "- **Python Code**:\n",
    "  - Data loading\n",
    "  - Data cleaning and preprocessing\n",
    "  - Cohort assignment and metric calculations\n",
    "  - Visualization of trends and patterns\n",
    "\n",
    "- **Visualizations**:\n",
    "  - Usage frequency over time\n",
    "  - Incident rate per cohort\n",
    "  - Revenue heatmap\n",
    "  - Custom metric visualization\n",
    "\n",
    "- **Optional**:\n",
    "  - Written summary or interpretation of findings\n",
    "  - Recommendations based on results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [🛠️ Data Analysis Tools](#️-data-analysis-tools)\n",
    "2. [📥 Importing Data](#-importing-data)\n",
    "3. [🔎 Exploratory Data Analysis (EDA)](#-exploratory-data-analysis-eda)\n",
    "4. [🧹 Data Cleaning / Quality Analysis](#-data-cleaning--quality-analysis)  \n",
    "5. [🔎 Exploratory Data Analysis (EDA) – Post-Cleanup](#-exploratory-data-analysis-eda--post-cleanup)\n",
    "6. [🎯 Metrics to Analyze](#-metrics-to-analyze)\n",
    "    - [Frequency of Service Usage](#frequency-of-service-usage)\n",
    "    - [Incident Rate](#incident-rate)\n",
    "    - [Revenue Generated by the Cohort](#revenue-generated-by-the-cohort)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 🛠️ Data Analysis Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "1124bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e82701",
   "metadata": {},
   "source": [
    "### Configure libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "03b19611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Seaborn context to \"poster\" for larger text and figures\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "# Set the default figure size for Seaborn plots\n",
    "sns.set_theme(rc={\"figure.figsize\": (12., 6.)})\n",
    "\n",
    "# Set the Seaborn style to \"whitegrid\" for a white background with gridlines\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3ba6f4",
   "metadata": {},
   "source": [
    "## 📥 Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "0fa26126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we removed the spaces from the csv files so we can easily import them here\n",
    "\n",
    "# lists of columns containing dates -> for parsing\n",
    "datetime_columns_cash_request = [\n",
    "    \"created_at\",\n",
    "    \"updated_at\",\n",
    "    \"moderated_at\",\n",
    "    \"cash_request_received_date\",\n",
    "    \"reimbursement_date\",\n",
    "    \"money_back_date\",\n",
    "    \"send_at\",\n",
    "    \"reco_last_update\",\n",
    "    \"reco_creation\"\n",
    "]\n",
    "   \n",
    "datetime_columns_fees = [\n",
    "    \"created_at\",\n",
    "    \"updated_at\",\n",
    "    \"paid_at\",\n",
    "    \"from_date\",\n",
    "    \"to_date\"\n",
    "]\n",
    "\n",
    "# We modified our import process to directly cast proper datatypes for dates.\n",
    "# Float/integer will still be handled in data cleaning, \n",
    "# since some of the offending columns have NaN values causing issues (hence presumably the wrong automatic casting)\n",
    "fees = pd.read_csv(\"../project_dataset/extract-fees-dataanalyst.csv\",\n",
    "                            parse_dates = datetime_columns_fees)\n",
    "cashRequest = pd.read_csv(\"../project_dataset/extract-cashrequest-dataanalyst.csv\", \n",
    "                            parse_dates = datetime_columns_cash_request)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f30c058",
   "metadata": {},
   "source": [
    "## 🔎 Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "497205b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we get a small insight in the data\n",
    "display(fees.head())\n",
    "# Overview of data in fees\n",
    "fees.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa623f37",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "- `cash_request_id` is automatically cast as float64. `int` might be more plausible, change in cleaning\n",
    "- date-related columns (`created_at`,`updated__at`,`paid_at`,`from_date`,`to_date`) will need special treatment \n",
    "- after date casting at import still trouble for `paid_at`,`from_date`,`to_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "3e677c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cashRequest.head())\n",
    "# Overview of data in cashRequest\n",
    "cashRequest.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c1315",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "- `delete_account_id` and `user_id` needn't be floats (cast to int later)\n",
    "- date-related columns (`created_at`,`updated__at`,`moderated_at`...) will need special treatment\n",
    "- fewer unique `user_id` values than cashRequest `id`s: indicating multiple transactions for some users or actual missing values?\n",
    "- after date casting at import the following fields are still `object` rather than `datetime`:\n",
    "  `moderated_at`,`reimbursement_date`,`money_back_date`,`send_at`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616659a9",
   "metadata": {},
   "source": [
    "## Function for evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "38a1b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One function to show all details about the dataframe\n",
    "def evaluateDataFrame(df):\n",
    "    # Lets check how many values we actually have\n",
    "    print(\"Total amount of records\")\n",
    "    print(len(df))\n",
    "    print()\n",
    "    # This shows us the amount of empty rows for each column \n",
    "    print(\"Empty rows\")\n",
    "    print(df.isna().sum())\n",
    "    print()\n",
    "    # check the number of unique values for each column \n",
    "    print(\"Unique rows\")\n",
    "    print(df.nunique())\n",
    "    print()\n",
    "    print(\"DataFrame info\")         \n",
    "    fees.info()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a9c616",
   "metadata": {},
   "source": [
    "### Use evaluateDataFrame to evaluate our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "e459c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# commented for now, piecewise presentation might be more readable in notebook \n",
    "\n",
    "evaluateDataFrame(cashRequest)\n",
    "evaluateDataFrame(fees)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a64390a",
   "metadata": {},
   "source": [
    "### Use inspect_data_types to get to know the differnce datatypes\n",
    "Only two types of fees are levied: 5 and 10 Euros(?) - maybe convert to int as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "95bf2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_data_types(df, name=\"DataFrame\"):\n",
    "    print(f\"=== {name} ===\")\n",
    "    numerical = df.select_dtypes(include='number').columns.tolist()\n",
    "    categorical = df.select_dtypes(include='object').columns.tolist()\n",
    "    datetime = df.select_dtypes(include=['datetime','datetime64','datetime64[ns, UTC]']).columns.tolist()\n",
    "      \n",
    "    print(f\"Numerical columns ({len(numerical)}): {numerical}\")\n",
    "    print(f\"Categorical columns ({len(categorical)}): {categorical}\")\n",
    "    print(f\"Date columns ({len(datetime)}): {datetime}\")\n",
    "    print()\n",
    "    \n",
    "    return numerical, categorical, datetime       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "92caf25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cashr_numcols, cashr_strcols, cashr_dtcols = inspect_data_types(cashRequest, name=\"cashRequest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "7c847d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fees_numcols, fees_strcols, fees_dtcols = inspect_data_types(fees, name=\"fees\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db517f7",
   "metadata": {},
   "source": [
    "Several of the date fields aren't typed correctly, fix in data cleaning and rerun function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4f960",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "- 2103 empty values in `cashRequest.user_id` corresponding to the difference to `id` noted above\n",
    "  - also: very close to value of `deleted_account` id (2104), so possible relation to that\n",
    "- fees are associated to cashRequests via `cash_request_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e7c2d",
   "metadata": {},
   "source": [
    "We used these insights to adapt our data import in order to directly cast the correct datatypes for columns that were not correctly identified automatically.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91415d5",
   "metadata": {},
   "source": [
    "## 🧹 Data Cleaning / Quality Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4b3feb",
   "metadata": {},
   "source": [
    "### Instructions after EDA\n",
    "1. Parse all values to the right data types\n",
    "2. remove loose items (like fees without cashRequest)\n",
    "3. Fill the user_id columns with deleted_account_id were empty because of account deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "1fa41786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the start and ends of all column names so we get no suprises in the data retrieval later\n",
    "fees.columns = fees.columns.str.strip()\n",
    "cashRequest.columns = cashRequest.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "72e7032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cashRequest['user_id'] = cashRequest['user_id'].fillna(cashRequest['deleted_account_id'])\n",
    "\n",
    "print(cashRequest['user_id'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d8bcc6",
   "metadata": {},
   "source": [
    "The next block is going to fix datatypes for both dataframes, i.e. fixing the missing dates and casting some columns as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "e186a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is antoher option of parsing datatypes\n",
    "# errors=\"coerce\" -> means that erroes will force conversion and replace any invalid or unconvertible values with NaT\n",
    "\n",
    "\n",
    "\n",
    "datetime_columns_cash_request = [\n",
    "    \"created_at\",\n",
    "    \"updated_at\",\n",
    "    \"moderated_at\",\n",
    "    \"cash_request_received_date\",\n",
    "    \"reimbursement_date\",\n",
    "    \"money_back_date\",\n",
    "    \"send_at\",\n",
    "    \"reco_last_update\",\n",
    "    \"reco_creation\"\n",
    "]\n",
    "\n",
    "for col in datetime_columns_cash_request:\n",
    "    cashRequest[col] = pd.to_datetime(cashRequest[col], errors=\"coerce\")\n",
    "    \n",
    "# the cash_request_received_date doesnt have an timezone so we normalize it to the standard utc\n",
    "cashRequest[\"cash_request_received_date\"] = cashRequest[\"cash_request_received_date\"].dt.tz_localize(\"UTC\")\n",
    "datetime_columns_fees = [\n",
    "    \"created_at\",\n",
    "    \"updated_at\",\n",
    "    \"paid_at\",\n",
    "    \"from_date\",\n",
    "    \"to_date\"\n",
    "]\n",
    "\n",
    "for col in datetime_columns_fees:\n",
    "    fees[col] = pd.to_datetime(fees[col], errors=\"coerce\")\n",
    "    \n",
    "\n",
    "\n",
    "float_to_int_fees = [\n",
    "    \"cash_request_id\",\n",
    "    \"id\"\n",
    "]\n",
    "\n",
    "# This currently doesn't work with astype(int), while astype(\"Int64\")\n",
    "for col in float_to_int_fees:\n",
    "    fees[col] = pd.to_numeric(fees[col], errors=\"coerce\").astype(\"Int64\")\n",
    "     \n",
    "float_to_int_cash_request = [\n",
    "    \"user_id\",\n",
    "    \"deleted_account_id\",\n",
    "    \"id\"\n",
    "]\n",
    "\n",
    "for col in float_to_int_cash_request:\n",
    "    cashRequest[col] = pd.to_numeric(cashRequest[col], errors=\"coerce\").astype(\"Int64\")\n",
    "    \n",
    "fees.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "4bbe27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cashr_numcols, cashr_strcols, cashr_dtcols = inspect_data_types(cashRequest, name=\"cashRequest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "021b17aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fees_numcols, fees_strcols, fees_dtcols = inspect_data_types(fees, name=\"fees\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357aacd",
   "metadata": {},
   "source": [
    "### Cleaning floats that should be ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "9f1ec013",
   "metadata": {},
   "outputs": [],
   "source": [
    "fees[fees['cash_request_id'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f5a4fa",
   "metadata": {},
   "source": [
    "NA-values in `fees.cash_request_id` are for cancelled transactions - let's drop them!(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "bf4610af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating copies before dropping values (optional)\n",
    "fees_cp = fees.copy()\n",
    "cashRequest_cp = cashRequest.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "6e87b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows that have are not connected to a cash request anymore\n",
    "fees_cp.dropna(subset=['cash_request_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf666ed5",
   "metadata": {},
   "source": [
    "### Checking NaT dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000aefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check date fields with missing data to assess significance\n",
    "for col in cashr_dtcols:\n",
    "    if cashRequest_cp[col].isna().sum() > 0:\n",
    "        print(col, ': ', cashRequest_cp[col].isna().sum())       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d189883f",
   "metadata": {},
   "source": [
    "### Creating column for cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "10a31ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column with the created_at converted to the month annotation like 2024-03-18, 2023-11-02 etc -> these can be used to be labels for the plot\n",
    "\n",
    "#add cohort month-assigns each row to a monthly cohort based on when the request was created (above) \n",
    "    #basically this just adds another column in the excel sheet called \"cohort\"\n",
    "cashRequest_cp['created_month'] = cashRequest_cp['created_at'].dt.to_period('M')\n",
    "\n",
    "cashRequest_cp['cohort'] = (\n",
    "    cashRequest_cp\n",
    "    .groupby('user_id')['created_month']\n",
    "    .transform('min')  # the user's first month\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6425da6e",
   "metadata": {},
   "source": [
    "\n",
    "## 🔎 Exploratory Data Analysis (EDA) – Post-Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb416ee",
   "metadata": {},
   "source": [
    "### Numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989a3777",
   "metadata": {},
   "source": [
    "#### Cash Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "3f9cb65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cashRequest_cp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed778fd5",
   "metadata": {},
   "source": [
    "`amount` is the only numerical variable where the statistics are meaningfully interpretable, since the others are just IDs.\n",
    "Cash request amounts ranged between 1€ and 200€ with the median at 100€ and a mean of just under 83€."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62405f3c",
   "metadata": {},
   "source": [
    "The histogram below illustrates this insight, with the majority of datapoints at 100€ and most of the remainder beneath that value.\n",
    "\n",
    "The further split-up by status also shows that almost all of the small amount requests (around 25€) have been successfully reimbursed. For amounts of 50 and 100, there is a noticable proportion of cancelled requests (probably just over half for 50€ and about 1/3 for the 100€ requests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "16cabbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fees_cp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93046adc",
   "metadata": {},
   "source": [
    "Fees ranged between 5 and 10€ with most of them at 5€ (given that the mean is almost at 5€)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "ed778fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(fees_cp,x='status',palette='colorblind', hue='status');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8961758",
   "metadata": {},
   "source": [
    "Most of the fees were successfully charged. A smaller number of fee bookings were cancelled (following the documentation mostly due to failed postpone fees, so there might be an expected correlation with `type` postpone). An even smaller number of fees had the `status` rejected, i.e. their charge had failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "54034459",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(fees_cp.type,fees_cp.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea77afd",
   "metadata": {},
   "source": [
    "Indeed, the overwhelming majority of rows with `status` cancelled are of `type` postpone. This is also reflected in the barplot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "b5e7f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total fees by type of fee\n",
    "sns.barplot(fees_cp,x='type',y='total_amount',hue='status',palette='colorblind',estimator=sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babac284",
   "metadata": {},
   "source": [
    "The major amount of fees comes from `instant_payment`s, a smaller amount from `postponement`s (of which more than half are actually cancelled) and the smallest amount comes from `incident`s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b27fdb",
   "metadata": {},
   "source": [
    "## Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "b3fc521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_status_counts = cashRequest_cp.status.value_counts()\n",
    "cr_status_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "b5e7f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group fees per Cash request and count the amount of fees for the cash request\n",
    "fee_counts = fees_cp.groupby(\"cash_request_id\").size().reset_index(name=\"fee_count\")\n",
    "\n",
    "# Visualizing\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(fee_counts[\"fee_count\"], bins=range(1, fee_counts[\"fee_count\"].max() + 2), kde=False)\n",
    "plt.title(\"Aantal fees per cash_request_id\")\n",
    "plt.xlabel(\"Aantal fees\")\n",
    "plt.ylabel(\"Aantal cash_request_id's\")\n",
    "plt.xticks(range(1, fee_counts[\"fee_count\"].max() + 1))\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "b3fc521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of amounts for cashrequests (not using the merged dataset here to avoid issues )\n",
    "sns.histplot(cashRequest_cp,x=\"amount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d48c8b",
   "metadata": {},
   "source": [
    "Most common cash advance requests were for 100€, followed by 50€ and some 25€ requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "3a303fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting histogram of amount\n",
    "sns.histplot(cashRequest_cp,x=\"amount\",y=\"status\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620c1104",
   "metadata": {},
   "source": [
    "## 🎯 Metrics to Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8008a9",
   "metadata": {},
   "source": [
    "\n",
    "### Frequency of Service Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "69efa381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group data\n",
    "cohort_counts = cashRequest_cp.groupby('cohort')['user_id'].count()\n",
    "\n",
    "# display(cohort_counts)\n",
    "created_counts = cashRequest_cp.groupby('created_month')['user_id'].count()\n",
    "# Convert Period to string if needed\n",
    "cohort_counts.index = cohort_counts.index.astype(str)\n",
    "created_counts.index = created_counts.index.astype(str)\n",
    "\n",
    "# Align indexes\n",
    "combined = pd.DataFrame({\n",
    "    'Cohort': cohort_counts,\n",
    "    'Created': created_counts\n",
    "}).fillna(0)  # in case some months are missing in one of the series\n",
    "\n",
    "# Plot as grouped bar chart\n",
    "ax = combined.plot(\n",
    "    kind='bar',\n",
    "    figsize=(14, 6),\n",
    "    width=0.8,  # controls total bar width\n",
    "    color=['steelblue', 'orange'],\n",
    "    title='User Counts: Cohort vs Created Month'\n",
    ")\n",
    "\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Type')\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb92a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get counts for users per cohort (courtesy of Jan above)\n",
    "cohort_counts = cashRequest_cp.groupby('cohort')['user_id'].nunique().reset_index()\n",
    "cohort_counts.rename(columns={'user_id':'user_count'},inplace=True)\n",
    "cohort_counts['cohort'] = cohort_counts['cohort'].astype(str)\n",
    "cohort_counts.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create groupby for cohort and month created\n",
    "cashReq_grouped = cashRequest_cp.groupby(['cohort', 'created_month'])['id'].count().reset_index()\n",
    "cashReq_grouped['cohort'] = cashReq_grouped['cohort'].astype(str)\n",
    "\n",
    "# renaming\n",
    "cashReq_grouped.rename(columns={'id': 'request_count'}, inplace=True)\n",
    "\n",
    "# merging with cohort_counts to get user numbers per cohort\n",
    "cashReq_grouped= cashReq_grouped.merge(cohort_counts,on='cohort',how='left')\n",
    "# calculate interactions per user\n",
    "cashReq_grouped['interactions_per_user'] = round(cashReq_grouped['request_count'] / cashReq_grouped['user_count'],3)\n",
    "\n",
    "# retyping and reformatting\n",
    "cashReq_grouped['created_month_dt'] = cashReq_grouped['created_month'].dt.to_timestamp()\n",
    "cashReq_grouped['created_month_str'] = cashReq_grouped['created_month_dt'].dt.strftime('%Y-%m')\n",
    "\n",
    "# sorting\n",
    "cashReq_grouped.sort_values('created_month_dt', inplace=True)\n",
    "\n",
    "cashReq_grouped.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e334c11b",
   "metadata": {},
   "source": [
    "Lineplot and barplot are suboptimal, especially due to the large numbers-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "48153d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create the lineplot\n",
    "sns.lineplot(\n",
    "    data=cashReq_grouped,\n",
    "    x='created_month_str',\n",
    "    y='request_count',\n",
    "    hue='cohort'\n",
    ")\n",
    "\n",
    "# layout\n",
    "plt.title('Cash Requests Over Time by Cohort')\n",
    "plt.xlabel('Created Month')\n",
    "plt.ylabel('Number of Requests')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cfb297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create the lineplot\n",
    "sns.barplot(\n",
    "    data=cashReq_grouped,\n",
    "    x='created_month_str',\n",
    "    y='request_count',\n",
    "    hue='cohort'\n",
    ")\n",
    "\n",
    "# layout\n",
    "plt.title('Cash Requests Over Time by Cohort')\n",
    "plt.xlabel('Created Month')\n",
    "plt.ylabel('Number of Requests')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb8d97",
   "metadata": {},
   "source": [
    "A heatmap representation allows representation of interaction counts per month for each cohort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "f21af26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = cashReq_grouped.pivot(index='cohort', columns='created_month_str', values='request_count')\n",
    "pivot = pivot.astype(float).fillna(0)  # Replace NaNs with 0\n",
    "\n",
    "sns.heatmap(pivot, cmap='Greens', annot=True, fmt='g')\n",
    "plt.title('Cash Request Utilisation by Cohort over Time')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Cohort')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917efb5",
   "metadata": {},
   "source": [
    "Alternatively, we can relativise the interaction counts to the cohort size to account for different total numbers. The diagonal values are at least 1 because the number of cohort members gets instated by their first interaction with the system. The very small first column automatically gets very \"strong\" values even though a cohort of 1 member may not be that informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "7a668663",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = cashReq_grouped.pivot(index='cohort', columns='created_month_str', values='interactions_per_user')\n",
    "pivot = pivot.astype(float).fillna(0)  # Replace NaNs with 0\n",
    "\n",
    "sns.heatmap(pivot, cmap='Greens', annot=True, fmt='g')\n",
    "plt.title('Cash Request Utilisation per User by Cohort over Time')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Cohort')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "e408dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative attempt, can maybe be ignored\n",
    "sns.histplot(cashReq_grouped,x='created_month_str',y='request_count',hue='cohort')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f6a42",
   "metadata": {},
   "source": [
    "### Incident Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c1104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a collection of all fees and left join the cashRequest data on it\n",
    "cashRequestFees = fees.merge(cashRequest_cp, how='left', left_on='cash_request_id', right_on='id')\n",
    "\n",
    "# Count number of items per (cohort, type)\n",
    "incident_count = cashRequestFees.groupby(['cohort', 'type']).size().unstack(fill_value=0)\n",
    "print(\"incident count:\")\n",
    "display(incident_count)\n",
    "print()\n",
    "\n",
    "# Get total rows per cohort\n",
    "cohort_totals = incident_count.sum(axis=1)\n",
    "print(\"Cohort totals:\")\n",
    "display(cohort_totals)\n",
    "print()\n",
    "\n",
    "# Calculate incident rate per status (per cohort)\n",
    "incident_rate = incident_count.divide(cohort_totals, axis=0)\n",
    "print(\"incident_rate:\")\n",
    "print(incident_rate.head())\n",
    "print()\n",
    "\n",
    "# Clean up column names: remove underscores and make it a title\n",
    "incident_rate.columns = [col.replace('_', ' ').title() for col in incident_rate.columns]\n",
    "print(\"columns:\")\n",
    "print(incident_rate.columns)\n",
    "print()\n",
    "\n",
    "# Plot as stacked bar chart\n",
    "incident_rate.plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    figsize=(14, 6),\n",
    "    colormap='tab20',\n",
    "    title='Incident Rate per Status per Cohort Month'\n",
    ")\n",
    "\n",
    "plt.xlabel('Cohort Month')\n",
    "plt.ylabel('Incident amount')\n",
    "plt.legend(title='Status', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cffd6b",
   "metadata": {},
   "source": [
    "### Revenue Generated by the Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ff626",
   "metadata": {},
   "outputs": [],
   "source": [
    "##3. **Revenue Generated by the Cohort:** Calculate the total revenue generated by each cohort over months to assess the financial impact of user behavior.\n",
    "# Merge revenue info from fees: \n",
    "    #1. make smaller version of the fees DF that has: which cash_request_id was charged, how much was charged (total_amount)\n",
    "    #2.renames cash_request_id to match the id column in cashRequest\n",
    "    #3.Merges them w my copy of cashRequest  (if the ids match) to add a new column (total_amount from fees) to the cashrequest copy. Merged left so we keep all the cash requests even if they are NaN for fees.  \n",
    "fees_cp = fees[[\"cash_request_id\", \"total_amount\"]].copy()\n",
    "fees_cp = fees_cp.rename(columns={\"cash_request_id\": \"id\"})\n",
    "cashRequest_cp = cashRequest_cp.merge(fees_cp, on=\"id\", how=\"left\")\n",
    "\n",
    "# Add request month column to cashrequstcp: tracks when each cash request was made (monthly) and allows for 2D table;\n",
    "    #request_month is specific to each cash request so its specific to each transaction! It can repeat if users make multipe requests each month and it can very for the same user in different months. \n",
    "        #we need this to analyze the total revenue generated by each cohort OVER MONTHS. WIthout it we only know the revenue from each cohort!\n",
    "    #cohort is specific to each user and doesnt change across rows for the same user. We need this to group users into cohorts.\n",
    "    #2D table: #rows (when joined-cohort, columns-when request was made, values-revenue in that month)\n",
    "    #allows you to analyze how revenue changes over time for each group of created_at (the cohort)\n",
    "cashRequest_cp[\"request_month\"] = cashRequest_cp[\"created_at\"].dt.to_period(\"M\")\n",
    "##3. **Revenue Generated by the Cohort:** Calculate the total revenue generated by each cohort over months to assess the financial impact of user behavior.\n",
    "\n",
    "#tells you how many requests (txns) were made each month\n",
    "cashRequest_cp[\"request_month\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae6dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "##3. **Revenue Generated by the Cohort:** Calculate the total revenue generated by each cohort over months to assess the financial impact of user behavior.\n",
    "\n",
    "#VISUALIZATION\n",
    "# Group and calculate total revenue (total_amount) per cohort per request month\n",
    "    #groups data by: cohort (when joined)\n",
    "    #request_month (when revenue happened)\n",
    "\n",
    "revenue_by_cohort = (\n",
    "    cashRequest_cp\n",
    "    .groupby([\"cohort\", \"request_month\"])[\"total_amount\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "# Optional: pivot the data to see it as a heatmap...doesnt do anything in this context of code.\n",
    "    #turns the grouped table into a matrix (rows=cohort, columns=months, values=revenue)\n",
    "revenue_pivot = revenue_by_cohort.pivot(index=\"cohort\", columns=\"request_month\", values=\"total_amount\")\n",
    "\n",
    "# Plot the heatmap\n",
    "    #blue=revenue...lets you see what cohorts bring the most $ over time. \n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(revenue_pivot, cmap=\"Blues\", annot=True, fmt=\".0f\")\n",
    "plt.title(\"Revenue by Cohort and Request Month\")\n",
    "plt.ylabel(\"Cohort Month\")\n",
    "plt.xlabel(\"Request Month\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
